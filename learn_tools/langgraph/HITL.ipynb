{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a593e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.types import Command\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72bd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    input: str\n",
    "    user_feedback : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_1(state:State):\n",
    "    print('---step1----')\n",
    "    pass\n",
    "\n",
    "def human_feedback(state:State):\n",
    "    '''Request assistance from human.'''\n",
    "    print('---Human Feedback----')\n",
    "    pass\n",
    "\n",
    "def step_3(state:State):\n",
    "    print(\"---step3---\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "builder.add_node(\"1\",step_1)\n",
    "builder.add_node(\"human\",human_feedback)\n",
    "builder.add_node(\"3\",step_3)\n",
    "builder.add_edge(START,\"1\")\n",
    "builder.add_edge(\"1\",\"human\")\n",
    "builder.add_edge(\"human\",\"3\")\n",
    "builder.add_edge(\"3\",END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "graph = builder.compile(checkpointer=memory,interrupt_before=['human'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I need some expert guidance and assistance for building an AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": user_input},\n",
    "    config=config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a0226",
   "metadata": {},
   "source": [
    "Here the output is just step1 meaning the first node executes but it requires human assistance and hence interrupted before step2 could execute.\n",
    "\n",
    "Now we will provide the required human assistance (in the form of command for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3c846",
   "metadata": {},
   "source": [
    "Hence after providing the Human command for the assistance, the step 3 got executed as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ae5b9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
